{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "00631df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from scipy) (1.24.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8973273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "     ---------------------------------------- 9.0/9.0 MB 4.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp39-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 4.2 MB/s eta 0:00:00\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp39-none-win_amd64.whl (287 kB)\n",
      "     -------------------------------------- 287.9/287.9 kB 4.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "     -------------------------------------- 401.2/401.2 kB 5.0 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "     -------------------------------------- 316.1/316.1 kB 4.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "Successfully installed fsspec-2024.5.0 huggingface-hub-0.23.0 safetensors-0.4.3 tokenizers-0.19.1 transformers-4.40.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "971cee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b2549d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retailers, the makers of foods marketed for we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Move over, Ozempic — there’s a new drug in tow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sept 14 (Reuters) - Bristol Myers Squibb (BMY....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austin Wolcott was 18 years old and pretty sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cancer, often referred to as the “emperor of a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  Retailers, the makers of foods marketed for we...\n",
       "1  Move over, Ozempic — there’s a new drug in tow...\n",
       "2  Sept 14 (Reuters) - Bristol Myers Squibb (BMY....\n",
       "3  Austin Wolcott was 18 years old and pretty sur...\n",
       "4  Cancer, often referred to as the “emperor of a..."
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = r\"C:\\Users\\Dell\\OneDrive\\Desktop\\Assignment.xlsx\"\n",
    "\n",
    "# Read the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bbbff7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df[\"Article\"][24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2b72eb91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Editorial Note: Blueprint may earn a commission from affiliate partner links featured here on our site. This commission does not influence our editors' opinions or evaluations. Please view our full advertiser disclosure policy .\\n\\n“Verified by an expert” means that this article has been thoroughly reviewed and evaluated for accuracy.\\n\\n“Verified by an expert” means that this article has been thoroughly reviewed and evaluated for accuracy.\\n\\nIf you’re considering opening a bank account with Wells Fargo, take note of the current promotions: You can earn a quick buck without too much effort.\\n\\nStill, a promotion shouldn’t be the only reason you open an account at a particular bank.\\n\\nAccount details and annual percentage yields (APYs) are accurate as of November 3, 2023.\\n\\nWells Fargo currently has a few promotions on some of its savings and checking accounts. Continue reading for promotion details and to find out how to qualify.\\n\\nNew Wells Fargo customers can earn a $300 bonus by opening a Wells Fargo Everyday Checking account in person or online with a $25 initial deposit.\\n\\nThe Everyday Checking is the bank’s most popular checking account. With a contactless debit card and features like Bill Pay, overdraft protection and Zelle, it’s got everything you need in a basic checking account — but nothing above and beyond.\\n\\nTo get the bonus, you must receive a total of $1,000 worth of qualifying electronic deposits within 90 days of opening your account.\\n\\nYou have to provide a bonus offer code when applying for your account in order to receive the bonus, which you can get by submitting your email address on the account promotion webpage.\\n\\nThe Everyday Checking account has a $10 monthly service fee. But you can avoid the fee by meeting one of the following requirements during each statement period:\\n• Receive $500 or more in total qualifying electronic deposits.\\n• Be between the ages of 17 and 24 — once you turn 25, age can no longer be used to avoid the fee.\\n• Link your account to a Wells Fargo Campus ATM Card or Campus Debit Card.\\n\\nThe Premier Checking account offers new customers a $2,500 bonus when they begin a banking relationship with Wells Fargo Premier. You can only open this account in person.\\n\\nIf you have a large enough balance to warrant it, you may want to consider the Premier Checking account. This interest-bearing account features special service discounts and tailored banking services. Additional features and perks include:\\n\\nWhile there’s no minimum balance requirement, there’s a $25 opening deposit and a $35 waivable monthly service fee. But unless you have a significant account balance, other Wells Fargo Checking accounts may be a better fit.\\n\\nYou can earn the $2,500 bonus by opening a Premier Checking account with an opening deposit of $25 and by meeting the following criteria:\\n• Bring at least $250,000 of new deposits to qualifying linked accounts within 45 days of account opening.\\n• Maintain a minimum balance of $250,000 through the first 90 days after account upgrade or opening.\\n\\nYou’ll also need to provide a bonus offer code — which you can get by providing your email address on the account promotion webpage — when you apply. You’ll need to bring this code with you to the bank, as this account is only available in person.\\n\\nThe Wells Fargo Premier Checking account has a $35 monthly service fee. But you can have the fee waived by having $250,000 or more in statement-ending qualified balances in linked accounts.\\n\\nCustomers new to saving with Wells Fargo can get a $525 bonus for opening a Way2Save® Savings account with a minimum deposit of $25. This account can only be opened in person.\\n\\nThe Wells Fargo Way2Save Savings account is a low-cost savings account you can open with just $25. But interest on this savings account is only 0.15% APY — nowhere near what you could earn by opening a savings account or certificate of deposit (CD) at many online banks.\\n\\nWith the Way2Save account, you can take advantage of Wells Fargo’s widespread presence. The account comes with an ATM card and access to more than 12,000 Wells Fargo ATMs. Other perks include mobile banking and optional overdraft protection.\\n\\nYou can earn a $525 bonus by opening a new Way2Save account with a $25 opening deposit and by doing the following:\\n• Deposit $25,000 or more into your new account within 30 days of opening.\\n• Maintain a balance of $25,000 through the first 90 days after account opening.\\n\\nYou’ll also need to provide a bonus offer code to the banker when opening your new account. You can get a code by providing your email address on the account promotion webpage.\\n\\nThe Way2Save savings account has a $5 monthly service fee, but you can avoid it by meeting one of these requirements each fee period:\\n• Make one automatic transfer of at least $25 each fee period from a linked Wells Fargo checking account.\\n• Make one automatic transfer of at least $1 each business day from a linked Wells Fargo checking account.\\n• Make one or more Save As You Go® transfers from a linked Wells Fargo checking account.\\n• Be under 25 years old.\\n\\nWells Fargo’s current promotions for its checking and savings accounts are noteworthy. Not all banks offer promotions, so the fact that you can earn a bonus with minimal effort is an advantage, no matter the cash value.\\n\\nWells Fargo’s current offers are comparable to those at other banks. For example, JPMorgan Chase Bank is offering a $200 bonus for opening a Chase Total Checking® account (offer expires Jan. 24, 2024) and Axos Bank® is offering a $300 bonus for opening a Rewards Checking account (offer expires Jan. 1, 2024). Citi Bank is currently advertising a bonus of up to $2,000 with a Citi® checking account, but you need a balance of $300,000 to earn it (offer expires Jan. 9, 2024). As far as competitors go, Wells Fargo’s bonuses, for the most part, match or exceed them.\\n\\nBut promotions aren’t the only thing to consider when opening a new bank account. Even though Wells Fargo offers impressive bonuses, its accounts have monthly fees and don’t earn much — if anything — in terms of interest. If you don’t qualify for waived monthly fees, you might be better off with a free checking account or high-yield savings account.\\n\\nFounded in 1852, Wells Fargo is one of the largest banks in the U.S. and has thousands of physical branches and ATMs throughout the country. Rates on savings accounts are low compared to high-yield savings accounts, but if you like to bank in person Wells Fargo is worth considering.\\n\\nThey offer a full range of banking products, including checking, savings, CDs, credit cards, loans, mortgages and investment services.\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa61b61",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75dcb147",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a4fd72f0524cfeb8be426cd5b13e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  31%|###       | 503M/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06070b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6eb05f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17508\\3132657251.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Generate Summary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msummary_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_ids\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0msummary_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   1450\u001b[0m             \u001b[1;31m# if model is encoder decoder encoder_outputs are created\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m             \u001b[1;31m# and added to `model_kwargs`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1452\u001b[1;33m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0m\u001b[0;32m   1453\u001b[0m                 \u001b[0minputs_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[1;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"return_dict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"encoder_outputs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1149\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_scale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0membed_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_positions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m         \u001b[0membed_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membed_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, past_key_values_length)\u001b[0m\n\u001b[0;32m    130\u001b[0m         ).expand(bsz, -1)\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositions\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    164\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2235\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2236\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2237\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "#Tokenizing\n",
    "inputs = tokenizer(text, max_length=1024, return_tensors=\"pt\")\n",
    "\n",
    "# Generate Summary\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], min_length=30, max_length=250,early_stopping=True)\n",
    "summary_output=tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "86286663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1818"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00df0fb",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8263c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bb177801b3468998ee2872ea6d7b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/933 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24d9dd1c31f4bd79e2689e4a4889dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/328M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4aec3bd1aa545ffb0d582c2340f2878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/333 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4733f5d49f774ec1afc3e9b8089d068d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00212e373d044a87a4f9897110ad324f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692c7bdff0fe4091ab9c2c0eed1c23b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3bc04e26834dfcbdd5ed92e0860ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for getting the sentiment score\n",
    "pipe = pipeline(\"text-classification\", model=\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a64bb4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291d3d5b",
   "metadata": {},
   "source": [
    "#### Generating the Sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "38d54c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_score(text):\n",
    "    \n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "    output=model(**encoded_text)\n",
    "    scores=output[0][0].detach().numpy()\n",
    "    scores=softmax(scores)\n",
    "    scores_dict={\n",
    "        \"Negative\": scores[0],\n",
    "        \"Neutral\" : scores[1],\n",
    "        \"Positive\": scores[2]\n",
    "    }\n",
    "    \n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90939577",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity_scores=polarity_score(summary_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef28c60",
   "metadata": {},
   "source": [
    "#### Selecting sentiment label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "26e2dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(scores_dict):\n",
    "    \n",
    "    # Convert dictionary values to a numpy array\n",
    "    sentiments_array = np.array(list(sentiments.values()))\n",
    "\n",
    "    # Find the index of the maximum value\n",
    "    max_index = np.argmax(sentiments_array)\n",
    "\n",
    "    # Get the corresponding sentiment label\n",
    "    sentiment_label = list(sentiments.keys())[max_index]\n",
    "\n",
    "    return sentiment_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dcdc2f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment=get_label(polarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dd1f35",
   "metadata": {},
   "source": [
    "# Final code for Summary and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bb4b5dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Your max_length is set to 80, but your input_length is only 70. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=35)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (668 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (668) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 668].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17508\\618879231.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m# Get sentiment score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m \u001b[0mpolarity_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sentiment_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentiment_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;31m# Get sentiment label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17508\\618879231.py\u001b[0m in \u001b[0;36mget_sentiment_score\u001b[1;34m(text, model, tokenizer)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_sentiment_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mencoded_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pt\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mencoded_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1189\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         outputs = self.roberta(\n\u001b[0m\u001b[0;32m   1192\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"token_type_ids\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[0mbuffered_token_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                 \u001b[0mbuffered_token_type_ids_expanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffered_token_type_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m                 \u001b[0mtoken_type_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffered_token_type_ids_expanded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The expanded size of the tensor (668) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [1, 668].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load pipelines\n",
    "summarize_pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\",tokenizer=\"facebook/bart-large-cnn\",framework=\"pt\")\n",
    "\n",
    "# summarized text generation\n",
    "def summarize_text(article,chunk_size=2048, summary_length=80, overlap=100):\n",
    "    # Initialize an empty list to store the summarized chunks\n",
    "    summarized_chunks = []\n",
    "\n",
    "    # Split the article into chunks\n",
    "    chunks = [article[i:i+chunk_size] for i in range(0, len(article), chunk_size)]\n",
    "\n",
    "    # Summarize each chunk\n",
    "    for chunk in chunks:\n",
    "        # Generate summary for the current chunk\n",
    "        summary = summarize_pipe(chunk, max_length=summary_length, min_length=20, do_sample=False)[0]['summary_text']\n",
    "        summarized_chunks.append(summary)\n",
    "    \n",
    "    # Concatenate the summarized chunks to form the final summary\n",
    "    final_summary = ' '.join(summarized_chunks)\n",
    "    return final_summary\n",
    "    \n",
    "\n",
    "# \n",
    "def load_model_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def get_sentiment_score(text, model, tokenizer):\n",
    "    encoded_text = tokenizer(text, return_tensors=\"pt\",)\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        \"Negative\": scores[0], \n",
    "        \"Neutral\": scores[1], \n",
    "        \"Positive\": scores[2]}\n",
    "    \n",
    "    return scores_dict\n",
    "\n",
    "def get_sentiment_label(scores_dict):\n",
    "    return max(scores_dict, key=scores_dict.get)\n",
    "\n",
    "# # Load data\n",
    "# file_path = r\"C:\\Users\\Dell\\OneDrive\\Desktop\\Assignment.xlsx\"\n",
    "# df = pd.read_excel(file_path)\n",
    "# text = df[\"Article\"][20]\n",
    " \n",
    "\n",
    "# Summarize text\n",
    "summary_output = summarize_text(text)\n",
    "\n",
    "# Load sentiment classification model and tokenizer\n",
    "tokenizer, sentiment_model = load_model_tokenizer(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "\n",
    "# Get sentiment score\n",
    "polarity_scores = get_sentiment_score(summary_output, sentiment_model, tokenizer)\n",
    "\n",
    "# Get sentiment label\n",
    "sentiment_label = get_sentiment_label(polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd90d7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\dell\\anaconda3\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\lib\\site-packages (from tqdm) (0.4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\dell\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2f87e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df.drop(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4d3a6742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows:  71%|██████████████████████████████████████████████                   | 17/24 [05:33<01:10, 10.14s/it]Your max_length is set to 80, but your input_length is only 42. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n",
      "Processing Rows: 100%|█████████████████████████████████████████████████████████████████| 24/24 [18:02<00:00, 45.09s/it]\n",
      "Getting Sentiment: 100%|███████████████████████████████████████████████████████████████| 24/24 [00:05<00:00,  4.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# # Apply the code for each row with tqdm\n",
    "tqdm.pandas(desc=\"Processing Rows\")\n",
    "df[\"Summary\"] = df[\"Article\"].progress_apply(summarize_text)\n",
    "\n",
    "# # Load sentiment classification model and tokenizer\n",
    "# tokenizer, sentiment_model = load_model_tokenizer(\"mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis\")\n",
    "\n",
    "# Get sentiment score and label for each row\n",
    "tqdm.pandas(desc=\"Getting Sentiment\")\n",
    "try:\n",
    "    df[[\"Polarity Scores\", \"Sentiment Label\"]] = df[\"Summary\"].progress_apply(\n",
    "    lambda x: pd.Series([get_sentiment_score(x, sentiment_model, tokenizer), get_sentiment_label(get_sentiment_score(x, sentiment_model, tokenizer))]))\n",
    "except:\n",
    "    print()\n",
    "# Display the updated DataFrame\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "abaa876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Negative': 0.0005089755, 'Neutral': 0.062238812, 'Positive': 0.9372522}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_score(df[\"Summary\"][2],sentiment_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d24bb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"AssigExcelFile.xlsx\", sheet_name=\"Subjects\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ea46c973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Polarity Scores</th>\n",
       "      <th>Sentiment Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Retailers, the makers of foods marketed for we...</td>\n",
       "      <td>Retailers, the makers of foods marketed for we...</td>\n",
       "      <td>{'Negative': 0.7718305, 'Neutral': 0.22352222,...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Move over, Ozempic — there’s a new drug in tow...</td>\n",
       "      <td>Eli Lilly’s Zepbound, with the active ingredie...</td>\n",
       "      <td>{'Negative': 0.0004442183, 'Neutral': 0.970779...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sept 14 (Reuters) - Bristol Myers Squibb (BMY....</td>\n",
       "      <td>Bristol Myers Squibb (BMY.N) said on Thursday ...</td>\n",
       "      <td>{'Negative': 0.9971073, 'Neutral': 0.000465487...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Austin Wolcott was 18 years old and pretty sur...</td>\n",
       "      <td>CAR-T therapy builds cells that outsmart cance...</td>\n",
       "      <td>{'Negative': 0.0002743454, 'Neutral': 0.001218...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cancer, often referred to as the “emperor of a...</td>\n",
       "      <td>Cancer is a complex amalgamation of diseases, ...</td>\n",
       "      <td>{'Negative': 0.0002463865, 'Neutral': 0.000544...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nov 28 (Reuters) - The U.S. Food and Drug Admi...</td>\n",
       "      <td>The FDA said it had received reports of T-cell...</td>\n",
       "      <td>{'Negative': 0.00031387864, 'Neutral': 0.99951...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nov 21 (Reuters) - BeiGene (6160.HK) said on T...</td>\n",
       "      <td>BeiGene has entered into an agreement with bio...</td>\n",
       "      <td>{'Negative': 0.00025849813, 'Neutral': 0.00096...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sept 19 (Reuters) - Drugmaker BeiGene (6160.HK...</td>\n",
       "      <td>BeiGene says it will regain rights to develop ...</td>\n",
       "      <td>{'Negative': 0.00025610998, 'Neutral': 0.00092...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BRUKINSA is the first and only BTK inhibitor a...</td>\n",
       "      <td>BRUKINSA is the first and only BTK inhibitor a...</td>\n",
       "      <td>{'Negative': 0.00035289873, 'Neutral': 0.00021...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Whether you're looking for a quick bite to eat...</td>\n",
       "      <td>Labor Day is \"an annual celebration of the soc...</td>\n",
       "      <td>{'Negative': 0.00055427145, 'Neutral': 0.99922...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A federal judge in New York has dismissed a la...</td>\n",
       "      <td>The suit was one of several false advertising ...</td>\n",
       "      <td>{'Negative': 0.0014024957, 'Neutral': 0.005319...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The future of fast food delivery is here.\\n\\nD...</td>\n",
       "      <td>Chick-fil-A is testing drone delivery in a 1.2...</td>\n",
       "      <td>{'Negative': 0.00025197628, 'Neutral': 0.96563...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yum Brands topped Wall Street estimates for th...</td>\n",
       "      <td>Yum Brands reports better-than-expected third-...</td>\n",
       "      <td>{'Negative': 0.00025723816, 'Neutral': 7.03269...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>If you fancy Taco Bell's Nacho Fries, the fast...</td>\n",
       "      <td>Taco Bell has a new twist on its popular Nacho...</td>\n",
       "      <td>{'Negative': 6.050791e-05, 'Neutral': 0.999694...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Taco Bell is serving up its new Toasted Breakf...</td>\n",
       "      <td>Toasted Breakfast Tacos are made with eggs, me...</td>\n",
       "      <td>{'Negative': 7.22622e-05, 'Neutral': 0.9998553...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Article  \\\n",
       "0   Retailers, the makers of foods marketed for we...   \n",
       "1   Move over, Ozempic — there’s a new drug in tow...   \n",
       "2   Sept 14 (Reuters) - Bristol Myers Squibb (BMY....   \n",
       "3   Austin Wolcott was 18 years old and pretty sur...   \n",
       "4   Cancer, often referred to as the “emperor of a...   \n",
       "5   Nov 28 (Reuters) - The U.S. Food and Drug Admi...   \n",
       "6   Nov 21 (Reuters) - BeiGene (6160.HK) said on T...   \n",
       "7   Sept 19 (Reuters) - Drugmaker BeiGene (6160.HK...   \n",
       "8   BRUKINSA is the first and only BTK inhibitor a...   \n",
       "9   Whether you're looking for a quick bite to eat...   \n",
       "10  A federal judge in New York has dismissed a la...   \n",
       "11  The future of fast food delivery is here.\\n\\nD...   \n",
       "12  Yum Brands topped Wall Street estimates for th...   \n",
       "13  If you fancy Taco Bell's Nacho Fries, the fast...   \n",
       "14  Taco Bell is serving up its new Toasted Breakf...   \n",
       "\n",
       "                                              Summary  \\\n",
       "0   Retailers, the makers of foods marketed for we...   \n",
       "1   Eli Lilly’s Zepbound, with the active ingredie...   \n",
       "2   Bristol Myers Squibb (BMY.N) said on Thursday ...   \n",
       "3   CAR-T therapy builds cells that outsmart cance...   \n",
       "4   Cancer is a complex amalgamation of diseases, ...   \n",
       "5   The FDA said it had received reports of T-cell...   \n",
       "6   BeiGene has entered into an agreement with bio...   \n",
       "7   BeiGene says it will regain rights to develop ...   \n",
       "8   BRUKINSA is the first and only BTK inhibitor a...   \n",
       "9   Labor Day is \"an annual celebration of the soc...   \n",
       "10  The suit was one of several false advertising ...   \n",
       "11  Chick-fil-A is testing drone delivery in a 1.2...   \n",
       "12  Yum Brands reports better-than-expected third-...   \n",
       "13  Taco Bell has a new twist on its popular Nacho...   \n",
       "14  Toasted Breakfast Tacos are made with eggs, me...   \n",
       "\n",
       "                                      Polarity Scores Sentiment Label  \n",
       "0   {'Negative': 0.7718305, 'Neutral': 0.22352222,...        Negative  \n",
       "1   {'Negative': 0.0004442183, 'Neutral': 0.970779...         Neutral  \n",
       "2   {'Negative': 0.9971073, 'Neutral': 0.000465487...        Negative  \n",
       "3   {'Negative': 0.0002743454, 'Neutral': 0.001218...        Positive  \n",
       "4   {'Negative': 0.0002463865, 'Neutral': 0.000544...        Positive  \n",
       "5   {'Negative': 0.00031387864, 'Neutral': 0.99951...         Neutral  \n",
       "6   {'Negative': 0.00025849813, 'Neutral': 0.00096...        Positive  \n",
       "7   {'Negative': 0.00025610998, 'Neutral': 0.00092...        Positive  \n",
       "8   {'Negative': 0.00035289873, 'Neutral': 0.00021...        Positive  \n",
       "9   {'Negative': 0.00055427145, 'Neutral': 0.99922...         Neutral  \n",
       "10  {'Negative': 0.0014024957, 'Neutral': 0.005319...        Positive  \n",
       "11  {'Negative': 0.00025197628, 'Neutral': 0.96563...         Neutral  \n",
       "12  {'Negative': 0.00025723816, 'Neutral': 7.03269...        Positive  \n",
       "13  {'Negative': 6.050791e-05, 'Neutral': 0.999694...         Neutral  \n",
       "14  {'Negative': 7.22622e-05, 'Neutral': 0.9998553...         Neutral  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9c8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca31ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
